# test_onnx.py
import numpy as np
import pandas as pd
import onnxruntime as ort
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
import time
import json
import random
from datetime import datetime, timedelta
import warnings

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


class ComprehensiveONNXTester:
    """
    å…¨é¢çš„ONNXæ¨¡å‹æµ‹è¯•å™¨
    æ”¯æŒå•ä¸ªåºåˆ—é¢„æµ‹ã€æ‰¹é‡æµ‹è¯•ã€å®æ—¶æ•°æ®æ¨¡æ‹Ÿç­‰å¤šç§æµ‹è¯•åœºæ™¯
    """

    def __init__(self, onnx_path, scaler_path=None):
        self.onnx_path = onnx_path
        self.scaler_path = scaler_path
        self.scaler = None
        self.class_names = ['æ­£å¸¸', 'å¼‚å¸¸']

        print(f"ğŸš€ åˆå§‹åŒ–ONNXæ¨¡å‹æµ‹è¯•å™¨...")
        print(f"   - æ¨¡å‹è·¯å¾„: {onnx_path}")
        print(f"   - æ ‡å‡†åŒ–å™¨è·¯å¾„: {scaler_path}")

        # åˆå§‹åŒ–ONNXè¿è¡Œæ—¶
        self._initialize_onnx_session()

        # åŠ è½½æ ‡å‡†åŒ–å™¨
        if scaler_path:
            self._load_scaler()

        print(f"âœ… ONNXæ¨¡å‹æµ‹è¯•å™¨åˆå§‹åŒ–å®Œæˆ")

    def _initialize_onnx_session(self):
        """åˆå§‹åŒ–ONNXè¿è¡Œæ—¶ä¼šè¯"""
        try:
            # é…ç½®ä¼šè¯é€‰é¡¹
            sess_options = ort.SessionOptions()
            sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
            sess_options.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL

            # é…ç½®æ‰§è¡Œæä¾›è€…
            providers = ['CPUExecutionProvider']
            if ort.get_available_providers().__contains__('CUDAExecutionProvider'):
                providers.insert(0, 'CUDAExecutionProvider')

            # åˆ›å»ºæ¨ç†ä¼šè¯
            self.ort_session = ort.InferenceSession(
                self.onnx_path,
                sess_options,
                providers=providers
            )

            # è·å–è¾“å…¥è¾“å‡ºä¿¡æ¯
            self.input_name = self.ort_session.get_inputs()[0].name
            self.output_name = self.ort_session.get_outputs()[0].name
            self.input_shape = self.ort_session.get_inputs()[0].shape
            self.output_shape = self.ort_session.get_outputs()[0].shape

            print(f"   - æ‰§è¡Œæä¾›è€…: {self.ort_session.get_providers()}")
            print(f"   - è¾“å…¥åç§°: {self.input_name}")
            print(f"   - è¾“å…¥å½¢çŠ¶: {self.input_shape}")
            print(f"   - è¾“å‡ºåç§°: {self.output_name}")
            print(f"   - è¾“å‡ºå½¢çŠ¶: {self.output_shape}")

        except Exception as e:
            print(f"âŒ ONNXè¿è¡Œæ—¶åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise

    def _load_scaler(self):
        """åŠ è½½æ ‡å‡†åŒ–å™¨"""
        try:
            self.scaler = joblib.load(self.scaler_path)
            print(f"   - æ ‡å‡†åŒ–å™¨åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ æ ‡å‡†åŒ–å™¨åŠ è½½å¤±è´¥: {str(e)}")
            self.scaler = None

    def _preprocess_data(self, data):
        """æ•°æ®é¢„å¤„ç†"""
        if self.scaler is not None:
            # å¦‚æœæ˜¯å•ä¸ªæ ·æœ¬ï¼Œéœ€è¦reshape
            if data.ndim == 1:
                data = data.reshape(1, -1)
                data = self.scaler.transform(data).flatten()
            elif data.ndim == 2:
                data = self.scaler.transform(data)
            else:
                # å¯¹äº3Dæ•°æ®ï¼ˆæ‰¹é‡åºåˆ—ï¼‰ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
                original_shape = data.shape
                data = data.reshape(-1, data.shape[-1])
                data = self.scaler.transform(data)
                data = data.reshape(original_shape)

        return data.astype(np.float32)

    def _softmax(self, x):
        """Softmaxå‡½æ•°"""
        exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=-1, keepdims=True)

    def predict_single_sequence(self, sequence_data, verbose=True):
        """
        å•ä¸ªåºåˆ—é¢„æµ‹

        Args:
            sequence_data: å•ä¸ªåºåˆ—æ•°æ®ï¼Œå½¢çŠ¶ä¸º (sequence_length, features) æˆ– (features,)
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

        Returns:
            dict: åŒ…å«é¢„æµ‹ç»“æœçš„å­—å…¸
        """
        if verbose:
            print(f"\nğŸ” å•ä¸ªåºåˆ—é¢„æµ‹æµ‹è¯•")
            print(f"=" * 50)

        try:
            # æ•°æ®é¢„å¤„ç†
            if isinstance(sequence_data, list):
                sequence_data = np.array(sequence_data)

            # ç¡®ä¿æ•°æ®å½¢çŠ¶æ­£ç¡®
            if sequence_data.ndim == 1:
                # å¦‚æœæ˜¯1Dæ•°æ®ï¼Œå‡è®¾æ˜¯å•ä¸ªæ—¶é—´æ­¥çš„ç‰¹å¾
                sequence_data = sequence_data.reshape(1, -1)

            if sequence_data.shape[0] < 10:
                # å¦‚æœåºåˆ—é•¿åº¦ä¸è¶³10ï¼Œè¿›è¡Œå¡«å……æˆ–é‡å¤
                if verbose:
                    print(f"   âš ï¸  åºåˆ—é•¿åº¦ä¸è¶³10ï¼Œå½“å‰é•¿åº¦: {sequence_data.shape[0]}")

                # é‡å¤æœ€åä¸€ä¸ªæ—¶é—´æ­¥æ¥å¡«å……
                last_step = sequence_data[-1:, :]
                padding_needed = 10 - sequence_data.shape[0]
                padding = np.repeat(last_step, padding_needed, axis=0)
                sequence_data = np.vstack([sequence_data, padding])

            # å–æœ€å10ä¸ªæ—¶é—´æ­¥
            sequence_data = sequence_data[-10:, :]

            # é¢„å¤„ç†æ•°æ®
            processed_data = self._preprocess_data(sequence_data)

            # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
            input_data = processed_data.reshape(1, 10, -1)

            if verbose:
                print(f"   - è¾“å…¥æ•°æ®å½¢çŠ¶: {input_data.shape}")
                print(f"   - æ•°æ®èŒƒå›´: [{input_data.min():.4f}, {input_data.max():.4f}]")

            # æ‰§è¡Œæ¨ç†
            start_time = time.time()
            outputs = self.ort_session.run([self.output_name], {self.input_name: input_data})
            inference_time = time.time() - start_time

            # å¤„ç†è¾“å‡º
            logits = outputs[0][0]  # ç§»é™¤æ‰¹æ¬¡ç»´åº¦
            probabilities = self._softmax(logits.reshape(1, -1))[0]
            predicted_class = np.argmax(logits)
            confidence = probabilities[predicted_class]

            result = {
                'predicted_class': int(predicted_class),
                'predicted_label': self.class_names[predicted_class],
                'confidence': float(confidence),
                'probabilities': {
                    self.class_names[i]: float(prob)
                    for i, prob in enumerate(probabilities)
                },
                'logits': logits.tolist(),
                'inference_time_ms': inference_time * 1000,
                'input_shape': input_data.shape
            }

            if verbose:
                print(f"   - é¢„æµ‹ç»“æœ: {result['predicted_label']}")
                print(f"   - ç½®ä¿¡åº¦: {result['confidence']:.4f}")
                print(f"   - æ¨ç†æ—¶é—´: {result['inference_time_ms']:.2f} ms")
                print(f"   - æ¦‚ç‡åˆ†å¸ƒ:")
                for label, prob in result['probabilities'].items():
                    print(f"     * {label}: {prob:.4f}")

            return result

        except Exception as e:
            print(f"âŒ å•ä¸ªåºåˆ—é¢„æµ‹å¤±è´¥: {str(e)}")
            return None

    def test_file_prediction(self, test_file_path, max_samples=None, verbose=True):
        """
        æµ‹è¯•æ–‡ä»¶é¢„æµ‹

        Args:
            test_file_path: æµ‹è¯•æ–‡ä»¶è·¯å¾„
            max_samples: æœ€å¤§æµ‹è¯•æ ·æœ¬æ•°
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

        Returns:
            dict: æµ‹è¯•ç»“æœ
        """
        if verbose:
            print(f"\nğŸ“Š æµ‹è¯•æ–‡ä»¶é¢„æµ‹")
            print(f"=" * 50)
            print(f"   - æµ‹è¯•æ–‡ä»¶: {test_file_path}")

        try:
            # åŠ è½½æµ‹è¯•æ•°æ®
            df = pd.read_excel(test_file_path, sheet_name='ä¸»æ•°æ®é›†')

            feature_columns = ['heart_rate', 'spo2', 'respiratory_rate', 'temperature']
            features = df[feature_columns].values
            labels = df['status_label'].values

            # åˆ›å»ºåºåˆ—æ•°æ®
            sequence_length = 10
            sequences = []
            sequence_labels = []

            for i in range(len(features) - sequence_length + 1):
                seq = features[i:i + sequence_length]
                label = labels[i + sequence_length - 1]
                sequences.append(seq)
                sequence_labels.append(label)

            sequences = np.array(sequences)
            sequence_labels = np.array(sequence_labels)

            # é™åˆ¶æµ‹è¯•æ ·æœ¬æ•°
            if max_samples and len(sequences) > max_samples:
                indices = np.random.choice(len(sequences), max_samples, replace=False)
                sequences = sequences[indices]
                sequence_labels = sequence_labels[indices]

            if verbose:
                print(f"   - æ€»åºåˆ—æ•°: {len(sequences)}")
                print(f"   - åºåˆ—å½¢çŠ¶: {sequences.shape}")
                print(f"   - æ­£å¸¸æ ·æœ¬: {np.sum(sequence_labels == 0)}")
                print(f"   - å¼‚å¸¸æ ·æœ¬: {np.sum(sequence_labels == 1)}")

            # æ‰¹é‡é¢„æµ‹
            predictions = []
            probabilities = []
            inference_times = []

            batch_size = 32
            num_batches = (len(sequences) + batch_size - 1) // batch_size

            for i in range(num_batches):
                start_idx = i * batch_size
                end_idx = min((i + 1) * batch_size, len(sequences))
                batch_sequences = sequences[start_idx:end_idx]

                # é¢„å¤„ç†æ‰¹é‡æ•°æ®
                processed_batch = self._preprocess_data(batch_sequences)

                # æ‰§è¡Œæ¨ç†
                start_time = time.time()
                outputs = self.ort_session.run(
                    [self.output_name],
                    {self.input_name: processed_batch}
                )
                inference_time = time.time() - start_time

                # å¤„ç†è¾“å‡º
                batch_logits = outputs[0]
                batch_probs = self._softmax(batch_logits)
                batch_preds = np.argmax(batch_logits, axis=1)

                predictions.extend(batch_preds)
                probabilities.extend(batch_probs)
                inference_times.append(inference_time)

                if verbose and (i + 1) % 10 == 0:
                    print(f"   å¤„ç†è¿›åº¦: {i + 1}/{num_batches} æ‰¹æ¬¡")

            predictions = np.array(predictions)
            probabilities = np.array(probabilities)

            # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
            accuracy = accuracy_score(sequence_labels, predictions)

            # ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š
            report = classification_report(
                sequence_labels, predictions,
                target_names=self.class_names,
                output_dict=True
            )

            # è®¡ç®—ROCæ›²çº¿
            fpr, tpr, _ = roc_curve(sequence_labels, probabilities[:, 1])
            roc_auc = auc(fpr, tpr)

            result = {
                'accuracy': accuracy,
                'total_samples': len(sequence_labels),
                'correct_predictions': np.sum(predictions == sequence_labels),
                'classification_report': report,
                'roc_auc': roc_auc,
                'predictions': predictions.tolist(),
                'true_labels': sequence_labels.tolist(),
                'probabilities': probabilities.tolist(),
                'inference_times': inference_times,
                'avg_inference_time_ms': np.mean(inference_times) * 1000,
                'total_inference_time_s': np.sum(inference_times)
            }

            if verbose:
                print(f"\nğŸ“ˆ æµ‹è¯•ç»“æœ:")
                print(f"   - å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy * 100:.2f}%)")
                print(f"   - æ­£ç¡®é¢„æµ‹: {result['correct_predictions']}/{result['total_samples']}")
                print(f"   - ROC AUC: {roc_auc:.4f}")
                print(f"   - å¹³å‡æ¨ç†æ—¶é—´: {result['avg_inference_time_ms']:.2f} ms/batch")
                print(f"   - æ€»æ¨ç†æ—¶é—´: {result['total_inference_time_s']:.2f} s")

                print(f"\nğŸ“‹ è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
                for class_name in self.class_names:
                    class_metrics = report[class_name]
                    print(f"   {class_name}:")
                    print(f"     - ç²¾ç¡®ç‡: {class_metrics['precision']:.4f}")
                    print(f"     - å¬å›ç‡: {class_metrics['recall']:.4f}")
                    print(f"     - F1åˆ†æ•°: {class_metrics['f1-score']:.4f}")
                    print(f"     - æ”¯æŒæ•°: {class_metrics['support']}")

            # ç»˜åˆ¶ç»“æœå›¾è¡¨
            self._plot_test_results(sequence_labels, predictions, probabilities, fpr, tpr, roc_auc)

            return result

        except Exception as e:
            print(f"âŒ æµ‹è¯•æ–‡ä»¶é¢„æµ‹å¤±è´¥: {str(e)}")
            return None

    def simulate_realtime_monitoring(self, duration_minutes=5, data_interval_seconds=3,
                                                 anomaly_probability=0.15, verbose=True):
        """æœ€ç»ˆä¿®å¤ç‰ˆæœ¬çš„å®æ—¶å¥åº·ç›‘æµ‹æ¨¡æ‹Ÿ"""
        if verbose:
            print(f"\nâ±ï¸  å®æ—¶å¥åº·ç›‘æµ‹æ¨¡æ‹Ÿ")
            print(f"=" * 50)
            print(f"   - æ¨¡æ‹Ÿæ—¶é•¿: {duration_minutes} åˆ†é’Ÿ")
            print(f"   - é‡‡é›†é—´éš”: {data_interval_seconds} ç§’")
            print(f"   - å¼‚å¸¸æ¦‚ç‡: {anomaly_probability:.2%}")

        try:
            total_points = int((duration_minutes * 60) / data_interval_seconds)

            timestamps = []
            raw_data = []
            true_labels = []
            predictions = []
            confidences = []
            inference_times = []

            # å¥åº·æŒ‡æ ‡åŸºçº¿
            baseline_hr = 75
            baseline_spo2 = 98
            baseline_rr = 16
            baseline_temp = 36.5

            data_window = []
            start_time = datetime.now()

            for i in range(total_points):
                current_time = start_time + timedelta(seconds=i * data_interval_seconds)
                timestamps.append(current_time)

                # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ç‚¹
                is_anomaly = random.random() < anomaly_probability

                if is_anomaly:
                    hr = baseline_hr + random.gauss(25, 15)
                    spo2 = baseline_spo2 + random.gauss(-8, 5)
                    rr = baseline_rr + random.gauss(8, 4)
                    temp = baseline_temp + random.gauss(1.5, 0.8)
                    true_label = 1
                else:
                    hr = baseline_hr + random.gauss(0, 8)
                    spo2 = baseline_spo2 + random.gauss(0, 2)
                    rr = baseline_rr + random.gauss(0, 3)
                    temp = baseline_temp + random.gauss(0, 0.4)
                    true_label = 0

                # ç¡®ä¿æ•°æ®åœ¨åˆç†èŒƒå›´å†…
                hr = max(40, min(200, hr))
                spo2 = max(70, min(100, spo2))
                rr = max(8, min(40, rr))
                temp = max(35, min(42, temp))

                data_point = [hr, spo2, rr, temp]
                raw_data.append(data_point)
                true_labels.append(true_label)

                # æ›´æ–°æ»‘åŠ¨çª—å£
                data_window.append(data_point)
                if len(data_window) > 10:
                    data_window.pop(0)

                # å½“çª—å£å¡«æ»¡æ—¶å¼€å§‹é¢„æµ‹
                if len(data_window) == 10:
                    sequence_data = np.array(data_window)
                    result = self.predict_single_sequence(sequence_data, verbose=False)

                    if result:
                        predictions.append(result['predicted_class'])
                        confidences.append(result['confidence'])
                        inference_times.append(result['inference_time_ms'])

                        if verbose and (i + 1) % 20 == 0:
                            status = "å¼‚å¸¸" if result['predicted_class'] == 1 else "æ­£å¸¸"
                            print(f"   {current_time.strftime('%H:%M:%S')} - "
                                  f"çŠ¶æ€: {status}, ç½®ä¿¡åº¦: {result['confidence']:.3f}")
                    else:
                        predictions.append(-1)
                        confidences.append(0.0)
                        inference_times.append(0.0)
                else:
                    predictions.append(-1)
                    confidences.append(0.0)
                    inference_times.append(0.0)

            # è®¡ç®—æœ‰æ•ˆé¢„æµ‹çš„è¯„ä¼°æŒ‡æ ‡
            valid_indices = [i for i, pred in enumerate(predictions) if pred != -1]

            if valid_indices:
                valid_predictions = np.array([predictions[i] for i in valid_indices])
                valid_true_labels = np.array([true_labels[i] for i in valid_indices])
                valid_confidences = np.array([confidences[i] for i in valid_indices])

                accuracy = accuracy_score(valid_true_labels, valid_predictions)

                # æ£€æµ‹å¼‚å¸¸äº‹ä»¶ - ä¿®å¤æ—¶é—´æˆ³å¤„ç†
                anomaly_events = []
                for i in valid_indices:
                    if predictions[i] == 1 and confidences[i] > 0.7:
                        anomaly_events.append({
                            'timestamp': timestamps[i],  # ä¿æŒdatetimeå¯¹è±¡
                            'confidence': confidences[i],
                            'data': raw_data[i],
                            'true_anomaly': true_labels[i] == 1
                        })
            else:
                accuracy = 0.0
                valid_predictions = np.array([])
                valid_true_labels = np.array([])
                anomaly_events = []

            result = {
                'duration_minutes': duration_minutes,
                'total_data_points': total_points,
                'valid_predictions': len(valid_indices),
                'accuracy': accuracy,
                'timestamps': [t.isoformat() for t in timestamps],  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                'raw_data': raw_data,
                'true_labels': true_labels,
                'predictions': predictions,
                'confidences': confidences,
                'inference_times': inference_times,
                'anomaly_events': [
                    {
                        'timestamp': event['timestamp'].isoformat(),  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                        'confidence': event['confidence'],
                        'data': event['data'],
                        'true_anomaly': event['true_anomaly']
                    } for event in anomaly_events
                ],
                'avg_inference_time_ms': np.mean([t for t in inference_times if t > 0]),
                'total_anomalies_detected': len(anomaly_events),
                'true_anomalies': np.sum(true_labels)
            }

            if verbose:
                print(f"\nğŸ“Š å®æ—¶ç›‘æµ‹æ¨¡æ‹Ÿç»“æœ:")
                print(f"   - æ€»æ•°æ®ç‚¹: {total_points}")
                print(f"   - æœ‰æ•ˆé¢„æµ‹: {len(valid_indices)}")
                print(f"   - é¢„æµ‹å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy * 100:.2f}%)")
                print(f"   - æ£€æµ‹åˆ°å¼‚å¸¸äº‹ä»¶: {len(anomaly_events)}")
                print(f"   - å®é™…å¼‚å¸¸äº‹ä»¶: {np.sum(true_labels)}")
                print(f"   - å¹³å‡æ¨ç†æ—¶é—´: {result['avg_inference_time_ms']:.2f} ms")

                if anomaly_events:
                    print(f"\nâš ï¸  å¼‚å¸¸äº‹ä»¶è¯¦æƒ…:")
                    for i, event in enumerate(anomaly_events[:5]):
                        status = "âœ…" if event['true_anomaly'] else "âŒ"
                        # ä»datetimeå¯¹è±¡ç›´æ¥æ ¼å¼åŒ–
                        timestamp_obj = timestamps[valid_indices[i]] if i < len(valid_indices) else datetime.now()
                        timestamp_str = timestamp_obj.strftime('%H:%M:%S')
                        print(f"   {i + 1}. {timestamp_str} {status} "
                              f"ç½®ä¿¡åº¦: {event['confidence']:.3f}")

            return result

        except Exception as e:
            print(f"âŒ å®æ—¶ç›‘æµ‹æ¨¡æ‹Ÿå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return None

    def benchmark_performance(self, batch_sizes=[1, 8, 16, 32, 64], num_iterations=100):
        """
        æ€§èƒ½åŸºå‡†æµ‹è¯•

        Args:
            batch_sizes: ä¸åŒçš„æ‰¹æ¬¡å¤§å°
            num_iterations: æ¯ä¸ªæ‰¹æ¬¡å¤§å°çš„è¿­ä»£æ¬¡æ•°

        Returns:
            dict: æ€§èƒ½æµ‹è¯•ç»“æœ
        """
        print(f"\nâš¡ æ€§èƒ½åŸºå‡†æµ‹è¯•")
        print(f"=" * 50)

        results = {}

        for batch_size in batch_sizes:
            print(f"   æµ‹è¯•æ‰¹æ¬¡å¤§å°: {batch_size}")

            # ç”Ÿæˆæµ‹è¯•æ•°æ®
            test_data = np.random.randn(batch_size, 10, 4).astype(np.float32)

            # é¢„å¤„ç†æ•°æ®
            if self.scaler:
                original_shape = test_data.shape
                test_data = test_data.reshape(-1, test_data.shape[-1])
                test_data = self.scaler.transform(test_data)
                test_data = test_data.reshape(original_shape).astype(np.float32)

            # é¢„çƒ­
            for _ in range(10):
                _ = self.ort_session.run([self.output_name], {self.input_name: test_data})

            # æ­£å¼æµ‹è¯•
            inference_times = []
            for _ in range(num_iterations):
                start_time = time.time()
                _ = self.ort_session.run([self.output_name], {self.input_name: test_data})
                inference_time = time.time() - start_time
                inference_times.append(inference_time * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’

            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            avg_time = np.mean(inference_times)
            std_time = np.std(inference_times)
            min_time = np.min(inference_times)
            max_time = np.max(inference_times)
            throughput = batch_size / (avg_time / 1000)  # æ ·æœ¬/ç§’

            results[batch_size] = {
                'avg_time_ms': avg_time,
                'std_time_ms': std_time,
                'min_time_ms': min_time,
                'max_time_ms': max_time,
                'throughput_samples_per_sec': throughput,
                'per_sample_time_ms': avg_time / batch_size
            }

            print(f"     - å¹³å‡æ—¶é—´: {avg_time:.2f} Â± {std_time:.2f} ms")
            print(f"     - ååé‡: {throughput:.1f} æ ·æœ¬/ç§’")
            print(f"     - å•æ ·æœ¬æ—¶é—´: {avg_time / batch_size:.2f} ms")

        # ç»˜åˆ¶æ€§èƒ½å›¾è¡¨
        self._plot_performance_results(results)

        return results

    def _plot_test_results(self, true_labels, predictions, probabilities, fpr, tpr, roc_auc):
        """ç»˜åˆ¶æµ‹è¯•ç»“æœå›¾è¡¨"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))

        # æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(true_labels, predictions)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=self.class_names, yticklabels=self.class_names, ax=axes[0, 0])
        axes[0, 0].set_title('æ··æ·†çŸ©é˜µ')
        axes[0, 0].set_xlabel('é¢„æµ‹æ ‡ç­¾')
        axes[0, 0].set_ylabel('çœŸå®æ ‡ç­¾')

        # ROCæ›²çº¿
        axes[0, 1].plot(fpr, tpr, color='darkorange', lw=2,
                        label=f'ROCæ›²çº¿ (AUC = {roc_auc:.3f})')
        axes[0, 1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        axes[0, 1].set_xlim([0.0, 1.0])
        axes[0, 1].set_ylim([0.0, 1.05])
        axes[0, 1].set_xlabel('å‡æ­£ç‡')
        axes[0, 1].set_ylabel('çœŸæ­£ç‡')
        axes[0, 1].set_title('ROCæ›²çº¿')
        axes[0, 1].legend(loc="lower right")
        axes[0, 1].grid(True, alpha=0.3)

        # ç½®ä¿¡åº¦åˆ†å¸ƒ
        normal_probs = probabilities[true_labels == 0, 0]
        anomaly_probs = probabilities[true_labels == 1, 1]

        axes[1, 0].hist(normal_probs, bins=30, alpha=0.7, label='æ­£å¸¸æ ·æœ¬', color='green')
        axes[1, 0].hist(anomaly_probs, bins=30, alpha=0.7, label='å¼‚å¸¸æ ·æœ¬', color='red')
        axes[1, 0].set_xlabel('é¢„æµ‹ç½®ä¿¡åº¦')
        axes[1, 0].set_ylabel('é¢‘æ¬¡')
        axes[1, 0].set_title('ç½®ä¿¡åº¦åˆ†å¸ƒ')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)

        # é¢„æµ‹å‡†ç¡®æ€§éšç½®ä¿¡åº¦å˜åŒ–
        confidence_thresholds = np.arange(0.5, 1.0, 0.05)
        accuracies = []
        sample_counts = []

        for threshold in confidence_thresholds:
            high_conf_mask = np.max(probabilities, axis=1) >= threshold
            if np.sum(high_conf_mask) > 0:
                high_conf_acc = accuracy_score(
                    true_labels[high_conf_mask],
                    predictions[high_conf_mask]
                )
                accuracies.append(high_conf_acc)
                sample_counts.append(np.sum(high_conf_mask))
            else:
                accuracies.append(0)
                sample_counts.append(0)

        axes[1, 1].plot(confidence_thresholds, accuracies, 'b-o', linewidth=2, markersize=4)
        axes[1, 1].set_xlabel('ç½®ä¿¡åº¦é˜ˆå€¼')
        axes[1, 1].set_ylabel('å‡†ç¡®ç‡')
        axes[1, 1].set_title('å‡†ç¡®ç‡ vs ç½®ä¿¡åº¦é˜ˆå€¼')
        axes[1, 1].grid(True, alpha=0.3)

        # æ·»åŠ æ ·æœ¬æ•°é‡ä¿¡æ¯
        ax2 = axes[1, 1].twinx()
        ax2.plot(confidence_thresholds, sample_counts, 'r--', alpha=0.7, label='æ ·æœ¬æ•°é‡')
        ax2.set_ylabel('æ ·æœ¬æ•°é‡', color='red')
        ax2.tick_params(axis='y', labelcolor='red')

        plt.tight_layout()
        plt.savefig('onnx_test_results.png', dpi=300, bbox_inches='tight')
        plt.show()

    def _plot_realtime_results(self, result):
        """ç»˜åˆ¶å®æ—¶ç›‘æµ‹ç»“æœ"""
        fig, axes = plt.subplots(3, 1, figsize=(15, 12))

        # è½¬æ¢æ—¶é—´æˆ³
        timestamps = [datetime.fromisoformat(t) for t in result['timestamps']]

        # 1. å¥åº·æŒ‡æ ‡æ—¶é—´åºåˆ—
        raw_data = np.array(result['raw_data'])
        feature_names = ['å¿ƒç‡', 'è¡€æ°§é¥±å’Œåº¦', 'å‘¼å¸é¢‘ç‡', 'ä½“æ¸©']
        colors = ['red', 'blue', 'green', 'orange']

        for i, (name, color) in enumerate(zip(feature_names, colors)):
            axes[0].plot(timestamps, raw_data[:, i], label=name, color=color, alpha=0.7)

        axes[0].set_title('å¥åº·æŒ‡æ ‡æ—¶é—´åºåˆ—')
        axes[0].set_ylabel('æŒ‡æ ‡å€¼')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)

        # 2. é¢„æµ‹ç»“æœå’Œç½®ä¿¡åº¦
        valid_indices = [i for i, pred in enumerate(result['predictions']) if pred != -1]
        valid_timestamps = [timestamps[i] for i in valid_indices]
        valid_predictions = [result['predictions'][i] for i in valid_indices]
        valid_confidences = [result['confidences'][i] for i in valid_indices]

        # é¢„æµ‹ç»“æœ
        pred_colors = ['green' if pred == 0 else 'red' for pred in valid_predictions]
        axes[1].scatter(valid_timestamps, valid_predictions, c=pred_colors, alpha=0.7, s=30)
        axes[1].set_title('é¢„æµ‹ç»“æœ (0=æ­£å¸¸, 1=å¼‚å¸¸)')
        axes[1].set_ylabel('é¢„æµ‹ç±»åˆ«')
        axes[1].set_ylim(-0.5, 1.5)
        axes[1].grid(True, alpha=0.3)

        # 3. ç½®ä¿¡åº¦å˜åŒ–
        axes[2].plot(valid_timestamps, valid_confidences, 'purple', linewidth=2, alpha=0.8)
        axes[2].axhline(y=0.7, color='red', linestyle='--', alpha=0.7, label='é«˜ç½®ä¿¡åº¦é˜ˆå€¼')
        axes[2].set_title('é¢„æµ‹ç½®ä¿¡åº¦å˜åŒ–')
        axes[2].set_xlabel('æ—¶é—´')
        axes[2].set_ylabel('ç½®ä¿¡åº¦')
        axes[2].legend()
        axes[2].grid(True, alpha=0.3)

        # æ ‡è®°å¼‚å¸¸äº‹ä»¶
        for event in result['anomaly_events']:
            event_time = datetime.fromisoformat(event['timestamp'])
            for ax in axes:
                ax.axvline(x=event_time, color='red', alpha=0.5, linestyle=':')

        plt.tight_layout()
        plt.savefig('realtime_monitoring_results.png', dpi=300, bbox_inches='tight')
        plt.show()

    def _plot_performance_results(self, results):
        """ç»˜åˆ¶æ€§èƒ½æµ‹è¯•ç»“æœ"""
        batch_sizes = list(results.keys())
        avg_times = [results[bs]['avg_time_ms'] for bs in batch_sizes]
        throughputs = [results[bs]['throughput_samples_per_sec'] for bs in batch_sizes]
        per_sample_times = [results[bs]['per_sample_time_ms'] for bs in batch_sizes]

        fig, axes = plt.subplots(1, 3, figsize=(18, 5))

        # æ‰¹æ¬¡æ¨ç†æ—¶é—´
        axes[0].plot(batch_sizes, avg_times, 'b-o', linewidth=2, markersize=6)
        axes[0].set_xlabel('æ‰¹æ¬¡å¤§å°')
        axes[0].set_ylabel('å¹³å‡æ¨ç†æ—¶é—´ (ms)')
        axes[0].set_title('æ‰¹æ¬¡æ¨ç†æ—¶é—´')
        axes[0].grid(True, alpha=0.3)
        axes[0].set_xscale('log', base=2)

        # ååé‡
        axes[1].plot(batch_sizes, throughputs, 'g-o', linewidth=2, markersize=6)
        axes[1].set_xlabel('æ‰¹æ¬¡å¤§å°')
        axes[1].set_ylabel('ååé‡ (æ ·æœ¬/ç§’)')
        axes[1].set_title('æ¨¡å‹ååé‡')
        axes[1].grid(True, alpha=0.3)
        axes[1].set_xscale('log', base=2)

        # å•æ ·æœ¬æ¨ç†æ—¶é—´
        axes[2].plot(batch_sizes, per_sample_times, 'r-o', linewidth=2, markersize=6)
        axes[2].set_xlabel('æ‰¹æ¬¡å¤§å°')
        axes[2].set_ylabel('å•æ ·æœ¬æ¨ç†æ—¶é—´ (ms)')
        axes[2].set_title('å•æ ·æœ¬æ¨ç†æ—¶é—´')
        axes[2].grid(True, alpha=0.3)
        axes[2].set_xscale('log', base=2)

        plt.tight_layout()
        plt.savefig('performance_benchmark.png', dpi=300, bbox_inches='tight')
        plt.show()

    def stress_test(self, max_concurrent_requests=50, test_duration_seconds=60):
        """
        å‹åŠ›æµ‹è¯•

        Args:
            max_concurrent_requests: æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
            test_duration_seconds: æµ‹è¯•æŒç»­æ—¶é—´

        Returns:
            dict: å‹åŠ›æµ‹è¯•ç»“æœ
        """
        print(f"\nğŸ”¥ å‹åŠ›æµ‹è¯•")
        print(f"=" * 50)
        print(f"   - æœ€å¤§å¹¶å‘è¯·æ±‚: {max_concurrent_requests}")
        print(f"   - æµ‹è¯•æ—¶é•¿: {test_duration_seconds} ç§’")

        import threading
        import queue

        # ç»“æœé˜Ÿåˆ—
        result_queue = queue.Queue()
        error_queue = queue.Queue()

        # æµ‹è¯•æ•°æ®
        test_data = np.random.randn(1, 10, 4).astype(np.float32)
        if self.scaler:
            test_data = self.scaler.transform(test_data.reshape(-1, 4)).reshape(1, 10, 4).astype(np.float32)

        def worker():
            """å·¥ä½œçº¿ç¨‹å‡½æ•°"""
            while True:
                try:
                    start_time = time.time()
                    outputs = self.ort_session.run([self.output_name], {self.input_name: test_data})
                    inference_time = time.time() - start_time
                    result_queue.put(inference_time * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
                except Exception as e:
                    error_queue.put(str(e))

                time.sleep(0.01)  # çŸ­æš‚ä¼‘æ¯

        # å¯åŠ¨å·¥ä½œçº¿ç¨‹
        threads = []
        for _ in range(max_concurrent_requests):
            t = threading.Thread(target=worker, daemon=True)
            t.start()
            threads.append(t)

        print(f"   âœ… å·²å¯åŠ¨ {len(threads)} ä¸ªå·¥ä½œçº¿ç¨‹")

        # æ”¶é›†ç»“æœ
        start_time = time.time()
        inference_times = []
        errors = []

        while time.time() - start_time < test_duration_seconds:
            try:
                # æ”¶é›†æ¨ç†æ—¶é—´
                while not result_queue.empty():
                    inference_times.append(result_queue.get_nowait())

                # æ”¶é›†é”™è¯¯
                while not error_queue.empty():
                    errors.append(error_queue.get_nowait())

                time.sleep(0.1)
            except queue.Empty:
                continue

        # æœ€åæ”¶é›†å‰©ä½™ç»“æœ
        while not result_queue.empty():
            inference_times.append(result_queue.get_nowait())
        while not error_queue.empty():
            errors.append(error_queue.get_nowait())

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        if inference_times:
            total_requests = len(inference_times)
            avg_time = np.mean(inference_times)
            std_time = np.std(inference_times)
            min_time = np.min(inference_times)
            max_time = np.max(inference_times)
            p95_time = np.percentile(inference_times, 95)
            p99_time = np.percentile(inference_times, 99)
            throughput = total_requests / test_duration_seconds

            result = {
                'total_requests': total_requests,
                'total_errors': len(errors),
                'success_rate': (total_requests / (total_requests + len(errors))) if (total_requests + len(
                    errors)) > 0 else 0,
                'avg_time_ms': avg_time,
                'std_time_ms': std_time,
                'min_time_ms': min_time,
                'max_time_ms': max_time,
                'p95_time_ms': p95_time,
                'p99_time_ms': p99_time,
                'throughput_rps': throughput,
                'test_duration_s': test_duration_seconds,
                'concurrent_threads': max_concurrent_requests
            }

            print(f"\nğŸ“Š å‹åŠ›æµ‹è¯•ç»“æœ:")
            print(f"   - æ€»è¯·æ±‚æ•°: {total_requests}")
            print(f"   - é”™è¯¯æ•°: {len(errors)}")
            print(f"   - æˆåŠŸç‡: {result['success_rate']:.4f} ({result['success_rate'] * 100:.2f}%)")
            print(f"   - å¹³å‡å“åº”æ—¶é—´: {avg_time:.2f} Â± {std_time:.2f} ms")
            print(f"   - P95å“åº”æ—¶é—´: {p95_time:.2f} ms")
            print(f"   - P99å“åº”æ—¶é—´: {p99_time:.2f} ms")
            print(f"   - ååé‡: {throughput:.1f} è¯·æ±‚/ç§’")

            if errors:
                print(f"\nâŒ é”™è¯¯ç±»å‹:")
                error_types = {}
                for error in errors:
                    error_types[error] = error_types.get(error, 0) + 1
                for error_type, count in error_types.items():
                    print(f"   - {error_type}: {count} æ¬¡")

            return result
        else:
            print(f"âŒ å‹åŠ›æµ‹è¯•å¤±è´¥ï¼šæ²¡æœ‰æˆåŠŸçš„è¯·æ±‚")
            return None

    def export_test_report(self, test_results, output_file='onnx_test_report.json'):
        """
        å¯¼å‡ºæµ‹è¯•æŠ¥å‘Š

        Args:
            test_results: æµ‹è¯•ç»“æœå­—å…¸
            output_file: è¾“å‡ºæ–‡ä»¶å
        """
        print(f"\nğŸ“„ å¯¼å‡ºæµ‹è¯•æŠ¥å‘Š: {output_file}")

        # å‡†å¤‡æŠ¥å‘Šæ•°æ®
        report = {
            'test_timestamp': datetime.now().isoformat(),
            'model_info': {
                'onnx_path': self.onnx_path,
                'scaler_path': self.scaler_path,
                'input_shape': self.input_shape,
                'output_shape': self.output_shape,
                'providers': self.ort_session.get_providers()
            },
            'test_results': test_results
        }

        # ä¿å­˜æŠ¥å‘Š
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)

        print(f"âœ… æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜")


def main():
    """ä¸»å‡½æ•°ï¼šå…¨é¢æµ‹è¯•ONNXæ¨¡å‹"""
    print("=" * 80)
    print("ğŸ§ª ONNXæ¨¡å‹å…¨é¢æµ‹è¯•å·¥å…·")
    print("=" * 80)

    # é…ç½®æ–‡ä»¶è·¯å¾„
    onnx_model_path = 'health_model_advanced.onnx'
    scaler_path = 'health_scaler.pkl'
    test_data_path = 'test_health_monitoring_dataset.xlsx'

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    import os
    required_files = [onnx_model_path, scaler_path, test_data_path]
    missing_files = [f for f in required_files if not os.path.exists(f)]

    if missing_files:
        print(f"âŒ ç¼ºå°‘ä»¥ä¸‹æ–‡ä»¶:")
        for f in missing_files:
            print(f"   - {f}")
        print("\nè¯·å…ˆè¿è¡Œ advanced_pth_to_onnx.py ç”ŸæˆONNXæ¨¡å‹")
        return

    try:
        # åˆå§‹åŒ–æµ‹è¯•å™¨
        tester = ComprehensiveONNXTester(onnx_model_path, scaler_path)

        # å­˜å‚¨æ‰€æœ‰æµ‹è¯•ç»“æœ
        all_results = {}

        # 1. å•ä¸ªåºåˆ—é¢„æµ‹æµ‹è¯•
        print("\n" + "=" * 80)
        print("ğŸ” æµ‹è¯•1: å•ä¸ªåºåˆ—é¢„æµ‹")
        print("=" * 80)

        # æµ‹è¯•æ­£å¸¸æ•°æ®
        normal_sequence = [
            [75, 98, 16, 36.5],  # æ­£å¸¸å¿ƒç‡ã€è¡€æ°§ã€å‘¼å¸ã€ä½“æ¸©
            [76, 97, 17, 36.6],
            [74, 98, 16, 36.4],
            [75, 98, 15, 36.5],
            [77, 97, 16, 36.6],
            [75, 98, 16, 36.5],
            [76, 98, 17, 36.5],
            [74, 97, 16, 36.4],
            [75, 98, 16, 36.5],
            [76, 98, 16, 36.6]
        ]

        print("\nğŸŸ¢ æµ‹è¯•æ­£å¸¸å¥åº·æ•°æ®:")
        normal_result = tester.predict_single_sequence(normal_sequence)

        # æµ‹è¯•å¼‚å¸¸æ•°æ®
        abnormal_sequence = [
            [95, 88, 25, 38.2],  # å¼‚å¸¸ï¼šé«˜å¿ƒç‡ã€ä½è¡€æ°§ã€å¿«å‘¼å¸ã€å‘çƒ­
            [98, 87, 26, 38.5],
            [100, 86, 27, 38.8],
            [102, 85, 28, 39.0],
            [105, 84, 30, 39.2],
            [108, 83, 32, 39.5],
            [110, 82, 34, 39.8],
            [112, 81, 35, 40.0],
            [115, 80, 36, 40.2],
            [118, 79, 38, 40.5]
        ]

        print("\nğŸ”´ æµ‹è¯•å¼‚å¸¸å¥åº·æ•°æ®:")
        abnormal_result = tester.predict_single_sequence(abnormal_sequence)

        all_results['single_sequence_tests'] = {
            'normal_data': normal_result,
            'abnormal_data': abnormal_result
        }

        # 2. æµ‹è¯•æ–‡ä»¶é¢„æµ‹
        print("\n" + "=" * 80)
        print("ğŸ“Š æµ‹è¯•2: æµ‹è¯•æ–‡ä»¶é¢„æµ‹")
        print("=" * 80)

        file_test_result = tester.test_file_prediction(test_data_path, max_samples=1000)
        all_results['file_prediction_test'] = file_test_result

        # 3. å®æ—¶ç›‘æµ‹æ¨¡æ‹Ÿ
        print("\n" + "=" * 80)
        print("â±ï¸  æµ‹è¯•3: å®æ—¶å¥åº·ç›‘æµ‹æ¨¡æ‹Ÿ")
        print("=" * 80)

        realtime_result = tester.simulate_realtime_monitoring(
            duration_minutes=5,  # 5åˆ†é’Ÿæ¨¡æ‹Ÿ
            data_interval_seconds=3,  # 3ç§’é‡‡é›†ä¸€æ¬¡
            anomaly_probability=0.15  # 15%å¼‚å¸¸æ¦‚ç‡
        )
        all_results['realtime_monitoring_test'] = realtime_result

        # 4. æ€§èƒ½åŸºå‡†æµ‹è¯•
        print("\n" + "=" * 80)
        print("âš¡ æµ‹è¯•4: æ€§èƒ½åŸºå‡†æµ‹è¯•")
        print("=" * 80)

        performance_result = tester.benchmark_performance(
            batch_sizes=[1, 2, 4, 8, 16, 32],
            num_iterations=50
        )
        all_results['performance_benchmark'] = performance_result

        # 5. å‹åŠ›æµ‹è¯•
        print("\n" + "=" * 80)
        print("ğŸ”¥ æµ‹è¯•5: å‹åŠ›æµ‹è¯•")
        print("=" * 80)

        stress_result = tester.stress_test(
            max_concurrent_requests=20,
            test_duration_seconds=30
        )
        all_results['stress_test'] = stress_result

        # 6. å¯¼å‡ºæµ‹è¯•æŠ¥å‘Š
        print("\n" + "=" * 80)
        print("ğŸ“„ ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š")
        print("=" * 80)

        tester.export_test_report(all_results, 'comprehensive_onnx_test_report.json')

        # 7. æ€»ç»“æŠ¥å‘Š
        print("\n" + "=" * 80)
        print("ğŸ‰ æµ‹è¯•å®Œæˆæ€»ç»“")
        print("=" * 80)

        print(f"âœ… å•ä¸ªåºåˆ—é¢„æµ‹æµ‹è¯•: å®Œæˆ")
        if normal_result and abnormal_result:
            print(f"   - æ­£å¸¸æ•°æ®é¢„æµ‹: {normal_result['predicted_label']} (ç½®ä¿¡åº¦: {normal_result['confidence']:.3f})")
            print(
                f"   - å¼‚å¸¸æ•°æ®é¢„æµ‹: {abnormal_result['predicted_label']} (ç½®ä¿¡åº¦: {abnormal_result['confidence']:.3f})")

        print(f"âœ… æµ‹è¯•æ–‡ä»¶é¢„æµ‹: å®Œæˆ")
        if file_test_result:
            print(f"   - æµ‹è¯•æ ·æœ¬æ•°: {file_test_result['total_samples']}")
            print(f"   - é¢„æµ‹å‡†ç¡®ç‡: {file_test_result['accuracy']:.4f}")
            print(f"   - ROC AUC: {file_test_result['roc_auc']:.4f}")

        print(f"âœ… å®æ—¶ç›‘æµ‹æ¨¡æ‹Ÿ: å®Œæˆ")
        if realtime_result:
            print(f"   - æ¨¡æ‹Ÿæ—¶é•¿: {realtime_result['duration_minutes']} åˆ†é’Ÿ")
            print(f"   - æ£€æµ‹å‡†ç¡®ç‡: {realtime_result['accuracy']:.4f}")
            print(f"   - å¼‚å¸¸äº‹ä»¶æ£€æµ‹: {realtime_result['total_anomalies_detected']} ä¸ª")

        print(f"âœ… æ€§èƒ½åŸºå‡†æµ‹è¯•: å®Œæˆ")
        if performance_result:
            best_throughput = max(performance_result.values(), key=lambda x: x['throughput_samples_per_sec'])
            print(f"   - æœ€ä½³ååé‡: {best_throughput['throughput_samples_per_sec']:.1f} æ ·æœ¬/ç§’")
            print(f"   - æœ€å¿«å•æ ·æœ¬æ¨ç†: {min(r['per_sample_time_ms'] for r in performance_result.values()):.2f} ms")

        print(f"âœ… å‹åŠ›æµ‹è¯•: å®Œæˆ")
        if stress_result:
            print(f"   - æˆåŠŸç‡: {stress_result['success_rate']:.4f}")
            print(f"   - ååé‡: {stress_result['throughput_rps']:.1f} è¯·æ±‚/ç§’")
            print(f"   - P95å“åº”æ—¶é—´: {stress_result['p95_time_ms']:.2f} ms")

        print(f"\nğŸ“Š æ‰€æœ‰æµ‹è¯•å›¾è¡¨å·²ä¿å­˜:")
        print(f"   - onnx_test_results.png")
        print(f"   - realtime_monitoring_results.png")
        print(f"   - performance_benchmark.png")
        print(f"   - comprehensive_onnx_test_report.json")

        print(f"\nğŸ¯ ONNXæ¨¡å‹æµ‹è¯•è¯„ä¼°:")
        if file_test_result and file_test_result['accuracy'] > 0.9:
            print(f"   ğŸŒŸ æ¨¡å‹æ€§èƒ½ä¼˜ç§€ (å‡†ç¡®ç‡ > 90%)")
        elif file_test_result and file_test_result['accuracy'] > 0.8:
            print(f"   âœ… æ¨¡å‹æ€§èƒ½è‰¯å¥½ (å‡†ç¡®ç‡ > 80%)")
        else:
            print(f"   âš ï¸  æ¨¡å‹æ€§èƒ½éœ€è¦æ”¹è¿›")

        if stress_result and stress_result['success_rate'] > 0.95:
            print(f"   ğŸŒŸ æ¨¡å‹ç¨³å®šæ€§ä¼˜ç§€ (æˆåŠŸç‡ > 95%)")
        elif stress_result and stress_result['success_rate'] > 0.9:
            print(f"   âœ… æ¨¡å‹ç¨³å®šæ€§è‰¯å¥½ (æˆåŠŸç‡ > 90%)")
        else:
            print(f"   âš ï¸  æ¨¡å‹ç¨³å®šæ€§éœ€è¦æ”¹è¿›")

        print("=" * 80)

    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # æ£€æŸ¥ä¾èµ–åŒ…
    required_packages = [
        'onnxruntime', 'pandas', 'numpy', 'matplotlib',
        'seaborn', 'sklearn', 'joblib'
    ]

    missing_packages = []
    for pkg in required_packages:
        try:
            __import__(pkg.replace('-', '_'))
        except ImportError:
            missing_packages.append(pkg)

    if missing_packages:
        print("âŒ ç¼ºå°‘ä»¥ä¸‹ä¾èµ–åŒ…:")
        for pkg in missing_packages:
            print(f"   - {pkg}")
        print(f"\nè¯·è¿è¡Œ: pip install {' '.join(missing_packages)}")
    else:
        print("âœ… æ‰€æœ‰ä¾èµ–åŒ…æ£€æŸ¥é€šè¿‡")
        main()

