import numpy as np
import onnxruntime as ort
import json
from datetime import datetime


class JSONStandardScaler:
    """åŸºäºJSONå‚æ•°çš„æ ‡å‡†åŒ–å™¨"""

    def __init__(self, json_path=None, scaler_params=None):
        if json_path:
            self.load_from_json(json_path)
        elif scaler_params:
            self.load_from_params(scaler_params)
        else:
            raise ValueError("å¿…é¡»æä¾›json_pathæˆ–scaler_params")

    def load_from_json(self, json_path):
        """ä»JSONæ–‡ä»¶åŠ è½½æ ‡å‡†åŒ–å‚æ•°"""
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                params = json.load(f)
            self.load_from_params(params)
            print(f"âœ… ä»JSONåŠ è½½æ ‡å‡†åŒ–å™¨: {json_path}")
        except Exception as e:
            print(f"âŒ JSONåŠ è½½å¤±è´¥: {str(e)}")
            raise

    def load_from_params(self, params):
        """ä»å‚æ•°å­—å…¸åŠ è½½"""
        # ç¡®ä¿æ‰€æœ‰å‚æ•°éƒ½æ˜¯float32ç±»å‹
        self.mean_ = np.array(params['mean'], dtype=np.float32)
        self.scale_ = np.array(params['scale'], dtype=np.float32)
        self.var_ = np.array(params['var'], dtype=np.float32)
        self.n_features_in_ = params['n_features_in']
        self.n_samples_seen_ = params['n_samples_seen']
        self.feature_names = params.get('feature_names', [])

    def transform(self, X):
        """æ ‡å‡†åŒ–æ•°æ®"""
        # ç¡®ä¿è¾“å…¥æ˜¯float32ç±»å‹
        X = np.array(X, dtype=np.float32)
        if X.ndim == 1:
            X = X.reshape(1, -1)

        # æ£€æŸ¥ç‰¹å¾æ•°é‡
        if X.shape[1] != self.n_features_in_:
            raise ValueError(f"è¾“å…¥ç‰¹å¾æ•°é‡({X.shape[1]})ä¸è®­ç»ƒæ—¶ä¸åŒ¹é…({self.n_features_in_})")

        # æ ‡å‡†åŒ–: (X - mean) / scaleï¼Œç¡®ä¿ç»“æœæ˜¯float32
        result = (X - self.mean_) / self.scale_
        return result.astype(np.float32)

    def inverse_transform(self, X):
        """åæ ‡å‡†åŒ–æ•°æ®"""
        X = np.array(X, dtype=np.float32)
        if X.ndim == 1:
            X = X.reshape(1, -1)

        # åæ ‡å‡†åŒ–: X * scale + mean
        result = X * self.scale_ + self.mean_
        return result.astype(np.float32)

    def get_feature_info(self):
        """è·å–ç‰¹å¾ä¿¡æ¯"""
        info = {}
        for i, name in enumerate(self.feature_names):
            info[name] = {
                'mean': float(self.mean_[i]),
                'std': float(np.sqrt(self.var_[i])),
                'scale': float(self.scale_[i])
            }
        return info


class HealthMonitorPredictor:
    """å¥åº·ç›‘æµ‹å•æ ·æœ¬é¢„æµ‹å™¨"""

    def __init__(self, onnx_model_path, scaler_json_path, sequence_length=10):
        self.sequence_length = sequence_length
        self.class_names = ['æ­£å¸¸', 'å¼‚å¸¸']

        # åŠ è½½ONNXæ¨¡å‹
        self.load_onnx_model(onnx_model_path)

        # åŠ è½½JSONæ ‡å‡†åŒ–å™¨
        self.scaler = JSONStandardScaler(scaler_json_path)

        print("ğŸ¯ å¥åº·ç›‘æµ‹é¢„æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")

    def load_onnx_model(self, onnx_path):
        """åŠ è½½ONNXæ¨¡å‹"""
        try:
            sess_options = ort.SessionOptions()
            sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL

            providers = ['CPUExecutionProvider']
            self.ort_session = ort.InferenceSession(onnx_path, sess_options, providers=providers)

            # æ£€æŸ¥è¾“å…¥è¾“å‡ºä¿¡æ¯
            input_info = self.ort_session.get_inputs()[0]
            print(f"âœ… ONNXæ¨¡å‹åŠ è½½æˆåŠŸ: {onnx_path}")
            print(f"   - è¾“å…¥åç§°: {input_info.name}")
            print(f"   - è¾“å…¥å½¢çŠ¶: {input_info.shape}")
            print(f"   - è¾“å…¥ç±»å‹: {input_info.type}")

        except Exception as e:
            print(f"âŒ ONNXæ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            raise

    def predict_single_sequence(self, sequence_data):
        """
        é¢„æµ‹å•ä¸ªåºåˆ—æ•°æ®

        Args:
            sequence_data: å½¢çŠ¶ä¸º (sequence_length, 4) çš„æ•°ç»„æˆ–åˆ—è¡¨
                          åŒ…å« [heart_rate, spo2, respiratory_rate, temperature]

        Returns:
            dict: åŒ…å«é¢„æµ‹ç»“æœçš„å­—å…¸
        """
        try:
            # æ•°æ®é¢„å¤„ç† - ç¡®ä¿æ˜¯float32ç±»å‹
            sequence_data = np.array(sequence_data, dtype=np.float32)

            # æ£€æŸ¥æ•°æ®å½¢çŠ¶
            if sequence_data.shape != (self.sequence_length, 4):
                raise ValueError(f"æ•°æ®å½¢çŠ¶åº”ä¸º({self.sequence_length}, 4)ï¼Œå®é™…ä¸º{sequence_data.shape}")

            print(f"ğŸ” è¾“å…¥æ•°æ®å½¢çŠ¶: {sequence_data.shape}, æ•°æ®ç±»å‹: {sequence_data.dtype}")

            # æ ‡å‡†åŒ–
            normalized_data = self.scaler.transform(sequence_data)
            print(f"ğŸ” æ ‡å‡†åŒ–åå½¢çŠ¶: {normalized_data.shape}, æ•°æ®ç±»å‹: {normalized_data.dtype}")

            # æ·»åŠ æ‰¹æ¬¡ç»´åº¦ (1, sequence_length, 4) - ç¡®ä¿æ˜¯float32
            input_data = normalized_data.reshape(1, self.sequence_length, 4).astype(np.float32)
            print(f"ğŸ” æ¨¡å‹è¾“å…¥å½¢çŠ¶: {input_data.shape}, æ•°æ®ç±»å‹: {input_data.dtype}")

            # ONNXæ¨ç†
            input_name = self.ort_session.get_inputs()[0].name
            outputs = self.ort_session.run(None, {input_name: input_data})

            # å¤„ç†è¾“å‡º
            logits = outputs[0][0]  # ç§»é™¤æ‰¹æ¬¡ç»´åº¦
            probabilities = self._softmax(logits)
            prediction = int(np.argmax(logits))
            confidence = float(probabilities[prediction])

            result = {
                'prediction': prediction,
                'prediction_label': self.class_names[prediction],
                'confidence': confidence,
                'probabilities': {
                    'æ­£å¸¸': float(probabilities[0]),
                    'å¼‚å¸¸': float(probabilities[1])
                },
                'raw_logits': logits.tolist(),
                'input_shape': input_data.shape,
                'input_dtype': str(input_data.dtype),
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }

            return result

        except Exception as e:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {str(e)}")
            return None

    def predict_single_sample(self, heart_rate, spo2, respiratory_rate, temperature,
                              previous_data=None):
        """
        é¢„æµ‹å•ä¸ªæ—¶é—´ç‚¹çš„æ•°æ®ï¼ˆéœ€è¦å†å²æ•°æ®æ„æˆåºåˆ—ï¼‰

        Args:
            heart_rate: å¿ƒç‡
            spo2: è¡€æ°§é¥±å’Œåº¦
            respiratory_rate: å‘¼å¸é¢‘ç‡
            temperature: ä½“æ¸©
            previous_data: ä¹‹å‰çš„æ•°æ®ï¼Œå½¢çŠ¶ä¸º (sequence_length-1, 4)

        Returns:
            dict: é¢„æµ‹ç»“æœ
        """
        if previous_data is None:
            # å¦‚æœæ²¡æœ‰å†å²æ•°æ®ï¼Œç”¨å½“å‰æ•°æ®é‡å¤å¡«å……
            print("âš ï¸  æ²¡æœ‰å†å²æ•°æ®ï¼Œä½¿ç”¨å½“å‰æ•°æ®é‡å¤å¡«å……åºåˆ—")
            current_sample = [float(heart_rate), float(spo2), float(respiratory_rate), float(temperature)]
            sequence_data = [current_sample] * self.sequence_length
        else:
            # ä½¿ç”¨å†å²æ•°æ® + å½“å‰æ•°æ®
            previous_data = np.array(previous_data, dtype=np.float32)
            if previous_data.shape[0] != self.sequence_length - 1:
                raise ValueError(f"å†å²æ•°æ®é•¿åº¦åº”ä¸º{self.sequence_length - 1}ï¼Œå®é™…ä¸º{previous_data.shape[0]}")

            current_sample = np.array([float(heart_rate), float(spo2), float(respiratory_rate), float(temperature)],
                                      dtype=np.float32)
            sequence_data = np.vstack([previous_data, current_sample.reshape(1, -1)])

        return self.predict_single_sequence(sequence_data)

    def _softmax(self, x):
        """Softmaxå‡½æ•°"""
        x = np.array(x, dtype=np.float32)
        exp_x = np.exp(x - np.max(x))
        return exp_x / np.sum(exp_x)

    def get_feature_statistics(self):
        """è·å–ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯"""
        return self.scaler.get_feature_info()


# ä¿®å¤çš„æ ‡å‡†åŒ–å™¨è½¬æ¢å‡½æ•°
def scaler_to_json(scaler_path, json_path):
    """å°†sklearn StandardScalerè½¬æ¢ä¸ºJSONæ ¼å¼"""
    try:
        import joblib

        # åŠ è½½æ ‡å‡†åŒ–å™¨
        scaler = joblib.load(scaler_path)

        # æå–æ ‡å‡†åŒ–å‚æ•°ï¼Œç¡®ä¿æ˜¯PythonåŸç”Ÿç±»å‹
        scaler_params = {
            'mean': [float(x) for x in scaler.mean_],
            'scale': [float(x) for x in scaler.scale_],
            'var': [float(x) for x in scaler.var_],
            'n_features_in': int(scaler.n_features_in_),
            'n_samples_seen': int(scaler.n_samples_seen_),
            'feature_names': ['heart_rate', 'spo2', 'respiratory_rate', 'temperature']
        }

        # ä¿å­˜ä¸ºJSON
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(scaler_params, f, indent=4, ensure_ascii=False)

        print(f"âœ… æ ‡å‡†åŒ–å™¨å·²è½¬æ¢ä¸ºJSONæ ¼å¼: {json_path}")
        print(f"   - ç‰¹å¾æ•°é‡: {scaler_params['n_features_in']}")
        print(f"   - è®­ç»ƒæ ·æœ¬æ•°: {scaler_params['n_samples_seen']}")
        print(f"   - ç‰¹å¾åç§°: {scaler_params['feature_names']}")
        print(f"   - æ•°æ®ç±»å‹: æ‰€æœ‰æ•°å€¼å·²è½¬æ¢ä¸ºPython floatç±»å‹")

        return scaler_params

    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {str(e)}")
        return None


def test_single_prediction():
    """æµ‹è¯•å•æ ·æœ¬é¢„æµ‹"""
    print("=" * 60)
    print("ğŸ§ª å¥åº·ç›‘æµ‹å•æ ·æœ¬é¢„æµ‹æµ‹è¯•")
    print("=" * 60)

    try:
        # åˆå§‹åŒ–é¢„æµ‹å™¨
        predictor = HealthMonitorPredictor(
            onnx_model_path='health_model_advanced.onnx',
            scaler_json_path='health_scaler.json'
        )

        # æ˜¾ç¤ºç‰¹å¾ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š ç‰¹å¾ç»Ÿè®¡ä¿¡æ¯:")
        feature_info = predictor.get_feature_statistics()
        for feature, stats in feature_info.items():
            print(f"   {feature}:")
            print(f"     - å‡å€¼: {stats['mean']:.2f}")
            print(f"     - æ ‡å‡†å·®: {stats['std']:.2f}")

        print("\n" + "=" * 40)
        print("ğŸ” æµ‹è¯•æ¡ˆä¾‹")
        print("=" * 40)

        # æµ‹è¯•æ¡ˆä¾‹1ï¼šæ­£å¸¸æ•°æ® - ä½¿ç”¨floatç±»å‹
        print("\nğŸ“‹ æµ‹è¯•æ¡ˆä¾‹1 - æ­£å¸¸ç”Ÿç†æŒ‡æ ‡:")
        normal_sequence = [
            [72.0, 98.0, 16.0, 36.5],  # æ˜ç¡®ä½¿ç”¨floatç±»å‹
            [74.0, 97.0, 17.0, 36.6],
            [71.0, 98.0, 16.0, 36.4],
            [73.0, 98.0, 18.0, 36.5],
            [75.0, 97.0, 16.0, 36.7],
            [72.0, 98.0, 17.0, 36.5],
            [74.0, 98.0, 16.0, 36.6],
            [73.0, 97.0, 17.0, 36.4],
            [71.0, 98.0, 16.0, 36.5],
            [72.0, 98.0, 16.0, 36.5]
        ]

        result1 = predictor.predict_single_sequence(normal_sequence)
        if result1:
            print(f"   é¢„æµ‹ç»“æœ: {result1['prediction_label']}")
            print(f"   ç½®ä¿¡åº¦: {result1['confidence']:.4f}")
            print(f"   æ¦‚ç‡åˆ†å¸ƒ: æ­£å¸¸={result1['probabilities']['æ­£å¸¸']:.4f}, "
                  f"å¼‚å¸¸={result1['probabilities']['å¼‚å¸¸']:.4f}")
            print(f"   è¾“å…¥æ•°æ®ç±»å‹: {result1['input_dtype']}")

        # æµ‹è¯•æ¡ˆä¾‹2ï¼šå¼‚å¸¸æ•°æ® - ä½¿ç”¨floatç±»å‹
        print("\nğŸ“‹ æµ‹è¯•æ¡ˆä¾‹2 - å¼‚å¸¸ç”Ÿç†æŒ‡æ ‡:")
        abnormal_sequence = [
            [120.0, 85.0, 25.0, 38.5],  # æ˜ç¡®ä½¿ç”¨floatç±»å‹
            [125.0, 84.0, 26.0, 38.7],
            [118.0, 86.0, 24.0, 38.6],
            [122.0, 83.0, 27.0, 38.8],
            [127.0, 82.0, 28.0, 38.9],
            [124.0, 84.0, 26.0, 38.7],
            [121.0, 85.0, 25.0, 38.6],
            [126.0, 83.0, 27.0, 38.8],
            [123.0, 84.0, 26.0, 38.7],
            [125.0, 82.0, 28.0, 38.9]
        ]

        result2 = predictor.predict_single_sequence(abnormal_sequence)
        if result2:
            print(f"   é¢„æµ‹ç»“æœ: {result2['prediction_label']}")
            print(f"   ç½®ä¿¡åº¦: {result2['confidence']:.4f}")
            print(f"   æ¦‚ç‡åˆ†å¸ƒ: æ­£å¸¸={result2['probabilities']['æ­£å¸¸']:.4f}, "
                  f"å¼‚å¸¸={result2['probabilities']['å¼‚å¸¸']:.4f}")
            print(f"   è¾“å…¥æ•°æ®ç±»å‹: {result2['input_dtype']}")

        # æµ‹è¯•æ¡ˆä¾‹3ï¼šå•ä¸ªæ—¶é—´ç‚¹é¢„æµ‹
        print("\nğŸ“‹ æµ‹è¯•æ¡ˆä¾‹3 - å•ä¸ªæ—¶é—´ç‚¹é¢„æµ‹:")

        # å†å²æ•°æ®ï¼ˆ9ä¸ªæ—¶é—´ç‚¹ï¼‰- ä½¿ç”¨floatç±»å‹
        history_data = [
            [70.0, 98.0, 15.0, 36.4],
            [72.0, 97.0, 16.0, 36.5],
            [71.0, 98.0, 15.0, 36.4],
            [73.0, 98.0, 17.0, 36.6],
            [74.0, 97.0, 16.0, 36.5],
            [72.0, 98.0, 16.0, 36.4],
            [71.0, 98.0, 15.0, 36.5],
            [73.0, 97.0, 17.0, 36.6],
            [72.0, 98.0, 16.0, 36.5]
        ]

        # å½“å‰æ—¶é—´ç‚¹æ•°æ®
        current_hr, current_spo2, current_rr, current_temp = 130.0, 80.0, 30.0, 39.0

        print(f"   å½“å‰ç”Ÿç†æŒ‡æ ‡: å¿ƒç‡={current_hr}, è¡€æ°§={current_spo2}, "
              f"å‘¼å¸é¢‘ç‡={current_rr}, ä½“æ¸©={current_temp}")

        result3 = predictor.predict_single_sample(
            current_hr, current_spo2, current_rr, current_temp,
            previous_data=history_data
        )

        if result3:
            print(f"   é¢„æµ‹ç»“æœ: {result3['prediction_label']}")
            print(f"   ç½®ä¿¡åº¦: {result3['confidence']:.4f}")
            print(f"   æ¦‚ç‡åˆ†å¸ƒ: æ­£å¸¸={result3['probabilities']['æ­£å¸¸']:.4f}, "
                  f"å¼‚å¸¸={result3['probabilities']['å¼‚å¸¸']:.4f}")
            print(f"   è¾“å…¥æ•°æ®ç±»å‹: {result3['input_dtype']}")

        print("\n" + "=" * 60)
        print("âœ… å•æ ·æœ¬é¢„æµ‹æµ‹è¯•å®Œæˆ!")
        print("=" * 60)

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


def interactive_prediction():
    """äº¤äº’å¼é¢„æµ‹"""
    print("\n" + "=" * 60)
    print("ğŸ¯ äº¤äº’å¼å¥åº·ç›‘æµ‹é¢„æµ‹")
    print("=" * 60)

    try:
        predictor = HealthMonitorPredictor(
            onnx_model_path='health_model_advanced.onnx',
            scaler_json_path='health_scaler.json'
        )

        print("\nè¯·è¾“å…¥ç”Ÿç†æŒ‡æ ‡æ•°æ®ï¼ˆè¾“å…¥'quit'é€€å‡ºï¼‰:")
        print("æ ¼å¼: å¿ƒç‡ è¡€æ°§é¥±å’Œåº¦ å‘¼å¸é¢‘ç‡ ä½“æ¸©")
        print("ç¤ºä¾‹: 72.0 98.0 16.0 36.5")

        sequence_data = []

        while True:
            try:
                user_input = input(f"\nç¬¬{len(sequence_data) + 1}ä¸ªæ•°æ®ç‚¹: ").strip()

                if user_input.lower() == 'quit':
                    break

                # è§£æè¾“å…¥ï¼Œç¡®ä¿æ˜¯floatç±»å‹
                values = [float(x) for x in user_input.split()]
                if len(values) != 4:
                    print("âŒ è¯·è¾“å…¥4ä¸ªæ•°å€¼ï¼šå¿ƒç‡ è¡€æ°§é¥±å’Œåº¦ å‘¼å¸é¢‘ç‡ ä½“æ¸©")
                    continue

                sequence_data.append(values)
                print(f"âœ… å·²è®°å½•: å¿ƒç‡={values[0]}, è¡€æ°§={values[1]}, "
                      f"å‘¼å¸é¢‘ç‡={values[2]}, ä½“æ¸©={values[3]}")

                # å½“æœ‰è¶³å¤Ÿæ•°æ®æ—¶è¿›è¡Œé¢„æµ‹
                if len(sequence_data) >= 10:
                    # ä½¿ç”¨æœ€è¿‘10ä¸ªæ•°æ®ç‚¹
                    recent_data = sequence_data[-10:]
                    result = predictor.predict_single_sequence(recent_data)

                    if result:
                        print(f"\nğŸ” é¢„æµ‹ç»“æœ:")
                        print(f"   çŠ¶æ€: {result['prediction_label']}")
                        print(f"   ç½®ä¿¡åº¦: {result['confidence']:.4f}")
                        print(f"   æ­£å¸¸æ¦‚ç‡: {result['probabilities']['æ­£å¸¸']:.4f}")
                        print(f"   å¼‚å¸¸æ¦‚ç‡: {result['probabilities']['å¼‚å¸¸']:.4f}")

                        if result['prediction'] == 1:  # å¼‚å¸¸
                            print("âš ï¸  æ£€æµ‹åˆ°å¼‚å¸¸çŠ¶æ€ï¼Œå»ºè®®å…³æ³¨!")
                        else:
                            print("âœ… ç”Ÿç†æŒ‡æ ‡æ­£å¸¸")

                elif len(sequence_data) < 10:
                    print(f"ğŸ“Š è¿˜éœ€è¦{10 - len(sequence_data)}ä¸ªæ•°æ®ç‚¹æ‰èƒ½è¿›è¡Œé¢„æµ‹")

            except ValueError:
                print("âŒ è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè¯·è¾“å…¥4ä¸ªæ•°å­—")
            except KeyboardInterrupt:
                print("\nğŸ‘‹ é€€å‡ºäº¤äº’å¼é¢„æµ‹")
                break
            except Exception as e:
                print(f"âŒ å¤„ç†é”™è¯¯: {str(e)}")

    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {str(e)}")


if __name__ == "__main__":
    # # 1. è½¬æ¢æ ‡å‡†åŒ–å™¨ä¸ºJSON
    # print("ğŸ”„ è½¬æ¢æ ‡å‡†åŒ–å™¨ä¸ºJSONæ ¼å¼...")
    # scaler_params = scaler_to_json('health_scaler.pkl', 'health_scaler.json')
    scaler_params = True
    if scaler_params:
        # 2. è¿è¡Œæµ‹è¯•
        test_single_prediction()

        # 3. äº¤äº’å¼é¢„æµ‹ï¼ˆå¯é€‰ï¼‰
        choice = input("\næ˜¯å¦å¯åŠ¨äº¤äº’å¼é¢„æµ‹ï¼Ÿ(y/n): ").strip().lower()
        if choice == 'y':
            interactive_prediction()
