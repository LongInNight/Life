import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
import joblib
import matplotlib.pyplot as plt


# æ¨¡å‹å®šä¹‰ï¼ˆä¸ä¹‹å‰ç›¸åŒï¼‰
class LSTMHealthMonitor(nn.Module):
    def __init__(self, input_size=4, hidden_size=64, num_layers=2, num_classes=2, dropout=0.2):
        super(LSTMHealthMonitor, self).__init__()

        self.hidden_size = hidden_size
        self.num_layers = num_layers

        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0,
            bidirectional=True
        )

        self.attention = nn.MultiheadAttention(
            embed_dim=hidden_size * 2,
            num_heads=8,
            dropout=dropout,
            batch_first=True
        )

        self.classifier = nn.Sequential(
            nn.Linear(hidden_size * 2, hidden_size),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_size // 2, num_classes)
        )

    def forward(self, x):
        batch_size = x.size(0)
        lstm_out, _ = self.lstm(x)
        attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)
        final_out = attn_out[:, -1, :]
        output = self.classifier(final_out)
        return output


def test_with_sample_data():
    """
    ä½¿ç”¨æä¾›çš„10ä¸ªæ•°æ®ç‚¹æµ‹è¯•æ¨¡å‹
    """
    print("=" * 80)
    print("ğŸ¥ ä½¿ç”¨æ ·æœ¬æ•°æ®æµ‹è¯•å¥åº·ç›‘æµ‹æ¨¡å‹")
    print("=" * 80)

    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")

    # 1. åˆ›å»ºæµ‹è¯•æ•°æ®
    print("\nğŸ“‚ å‡†å¤‡æµ‹è¯•æ•°æ®...")

    # æ ¹æ®å›¾ç‰‡ä¸­çš„æ•°æ®åˆ›å»ºDataFrame
    data = {
        'time_point': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
        'heart_rate': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        'spo2': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        'respiratory_rate': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        'temperature': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        'status_label': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  # å‡è®¾éƒ½æ˜¯æ­£å¸¸çŠ¶æ€
    }

    df = pd.DataFrame(data)
    print("âœ… æ•°æ®åˆ›å»ºæˆåŠŸ!")
    print(f"   - æ•°æ®å½¢çŠ¶: {df.shape}")
    print(f"\nğŸ“Š æ•°æ®æ¦‚è§ˆ:")
    print(df)

    # ç‰¹å¾åˆ—
    numeric_cols = ['heart_rate', 'spo2', 'respiratory_rate', 'temperature']

    # ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
    print(df[numeric_cols].describe())

    # 2. åˆå§‹åŒ–æ¨¡å‹ï¼ˆç”±äºæ²¡æœ‰é¢„è®­ç»ƒæ¨¡å‹ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–ï¼‰
    print(f"\nğŸ”§ åˆå§‹åŒ–æ¨¡å‹...")
    model = LSTMHealthMonitor(
        input_size=4,
        hidden_size=64,
        num_layers=2,
        num_classes=2,
        dropout=0.2
    )
    model.to(device)
    model.eval()
    print("âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ!")

    # 3. åŠ è½½æ ‡å‡†åŒ–å™¨
    print(f"\nğŸ”§ åŠ è½½æ ‡å‡†åŒ–å™¨...")
    try:
        scaler = joblib.load('health_scaler.pkl')
        print("âœ… æ ‡å‡†åŒ–å™¨åŠ è½½æˆåŠŸ!")

        # æ˜¾ç¤ºæ ‡å‡†åŒ–å‚æ•°
        print(f"   æ ‡å‡†åŒ–å‚æ•°:")
        for i, col in enumerate(numeric_cols):
            print(f"   - {col}: å‡å€¼={scaler.mean_[i]:.2f}, æ ‡å‡†å·®={scaler.scale_[i]:.2f}")

    except Exception as e:
        print(f"âŒ æ ‡å‡†åŒ–å™¨åŠ è½½å¤±è´¥: {str(e)}")
        print("âš ï¸  å°†ä½¿ç”¨å½“å‰æ•°æ®åˆ›å»ºæ–°çš„æ ‡å‡†åŒ–å™¨...")
        scaler = StandardScaler()
        feature_data_temp = df[numeric_cols].values
        scaler.fit(feature_data_temp)
        print("âœ… æ–°æ ‡å‡†åŒ–å™¨åˆ›å»ºæˆåŠŸ!")

    # 4. æ•°æ®é¢„å¤„ç†
    print(f"\nğŸ”§ æ•°æ®é¢„å¤„ç†...")

    # æå–ç‰¹å¾æ•°æ®
    feature_data = df[numeric_cols].values
    labels = df['status_label'].values

    # ä½¿ç”¨åŠ è½½çš„æ ‡å‡†åŒ–å™¨è¿›è¡Œæ ‡å‡†åŒ–
    feature_data_scaled = scaler.transform(feature_data)

    print(f"âœ… æ•°æ®æ ‡å‡†åŒ–å®Œæˆ!")
    print(f"   ä½¿ç”¨å·²è®­ç»ƒçš„æ ‡å‡†åŒ–å™¨å‚æ•°")

    # æ˜¾ç¤ºæ ‡å‡†åŒ–å‰åçš„æ•°æ®å¯¹æ¯”
    print(f"\nğŸ“‹ æ ‡å‡†åŒ–å‰åæ•°æ®å¯¹æ¯”:")
    print(f"{'å‚æ•°':<12} {'åŸå§‹èŒƒå›´':<15} {'æ ‡å‡†åŒ–èŒƒå›´':<15}")
    print("-" * 50)
    for i, col in enumerate(numeric_cols):
        orig_min, orig_max = np.min(feature_data[:, i]), np.max(feature_data[:, i])
        scaled_min, scaled_max = np.min(feature_data_scaled[:, i]), np.max(feature_data_scaled[:, i])
        print(f"{col:<12} {orig_min:.1f} - {orig_max:.1f}     {scaled_min:.2f} - {scaled_max:.2f}")

    # 5. åˆ›å»ºåºåˆ—ï¼ˆç”±äºåªæœ‰10ä¸ªæ•°æ®ç‚¹ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ª10æ­¥åºåˆ—ï¼‰
    print(f"\nğŸ“‹ åˆ›å»ºæµ‹è¯•åºåˆ—...")

    # ç”±äºæ•°æ®ç‚¹è¾ƒå°‘ï¼Œæˆ‘ä»¬ç›´æ¥ä½¿ç”¨å…¨éƒ¨10ä¸ªç‚¹ä½œä¸ºä¸€ä¸ªåºåˆ—
    sequence = feature_data_scaled.reshape(1, 10, 4)  # (1, seq_len, features)
    sequence_tensor = torch.FloatTensor(sequence).to(device)

    print(f"âœ… åºåˆ—åˆ›å»ºæˆåŠŸ!")
    print(f"   - åºåˆ—å½¢çŠ¶: {sequence.shape}")
    print(f"   - åºåˆ—é•¿åº¦: 10")
    print(f"   - ç‰¹å¾æ•°é‡: 4")

    # 6. æ¨¡å‹é¢„æµ‹
    print(f"\nğŸ”® å¼€å§‹é¢„æµ‹...")

    with torch.no_grad():
        outputs = model(sequence_tensor)
        probabilities = torch.softmax(outputs, dim=1)
        predictions = torch.argmax(outputs, dim=1)

    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    outputs_np = outputs.cpu().numpy()[0]
    probabilities_np = probabilities.cpu().numpy()[0]
    predictions_np = predictions.cpu().numpy()[0]

    print("âœ… é¢„æµ‹å®Œæˆ!")

    # 7. ç»“æœåˆ†æ
    print(f"\nğŸ“Š é¢„æµ‹ç»“æœåˆ†æ:")
    print("=" * 80)

    class_names = ['æ­£å¸¸', 'å¼‚å¸¸']
    predicted_class = class_names[predictions_np]
    normal_prob = probabilities_np[0]
    abnormal_prob = probabilities_np[1]
    confidence = max(normal_prob, abnormal_prob)

    print(f"ğŸ¯ é¢„æµ‹ç»“æœ:")
    print(f"   - é¢„æµ‹ç±»åˆ«: {predicted_class}")
    print(f"   - æ­£å¸¸æ¦‚ç‡: {normal_prob:.4f} ({normal_prob * 100:.2f}%)")
    print(f"   - å¼‚å¸¸æ¦‚ç‡: {abnormal_prob:.4f} ({abnormal_prob * 100:.2f}%)")
    print(f"   - é¢„æµ‹ç½®ä¿¡åº¦: {confidence:.4f} ({confidence * 100:.2f}%)")
    print(f"   - æ¨¡å‹åŸå§‹è¾“å‡º (logits): [{outputs_np[0]:.3f}, {outputs_np[1]:.3f}]")

    # 8. è¯¦ç»†æ•°æ®åˆ†æ
    print(f"\nğŸ” è¯¦ç»†æ•°æ®åˆ†æ:")
    print("-" * 80)

    print(f"ğŸ“‹ è¾“å…¥åºåˆ—è¯¦æƒ…:")
    print(f"{'æ—¶é—´ç‚¹':<6} {'å¿ƒç‡':<8} {'è¡€æ°§':<8} {'å‘¼å¸':<8} {'ä½“æ¸©':<8} {'æ ‡å‡†åŒ–å'}")
    print("-" * 80)

    for i in range(10):
        original = feature_data[i]
        scaled = feature_data_scaled[i]
        print(f"{i + 1:<6} {original[0]:<8.1f} {original[1]:<8.1f} {original[2]:<8.1f} {original[3]:<8.1f} "
              f"[{scaled[0]:.2f}, {scaled[1]:.2f}, {scaled[2]:.2f}, {scaled[3]:.2f}]")

    # 9. ç”Ÿç†å‚æ•°è¯„ä¼°
    print(f"\nğŸ¥ ç”Ÿç†å‚æ•°è¯„ä¼°:")
    print("-" * 60)

    # æ­£å¸¸èŒƒå›´å®šä¹‰
    normal_ranges = {
        'heart_rate': (60, 100),
        'spo2': (95, 100),
        'respiratory_rate': (12, 20),
        'temperature': (36.1, 37.2)
    }

    for i, param in enumerate(numeric_cols):
        values = feature_data[:, i]
        min_val, max_val = normal_ranges[param]
        mean_val = np.mean(values)
        std_val = np.std(values)

        # æ£€æŸ¥æ˜¯å¦åœ¨æ­£å¸¸èŒƒå›´å†…
        in_range = np.all((values >= min_val) & (values <= max_val))
        out_of_range_count = np.sum((values < min_val) | (values > max_val))

        status = "âœ… æ­£å¸¸" if in_range else f"âš ï¸  {out_of_range_count}ä¸ªå¼‚å¸¸å€¼"

        print(f"{param.replace('_', ' ').title()}:")
        print(f"   - èŒƒå›´: {np.min(values):.1f} - {np.max(values):.1f}")
        print(f"   - å‡å€¼Â±æ ‡å‡†å·®: {mean_val:.1f}Â±{std_val:.1f}")
        print(f"   - æ­£å¸¸èŒƒå›´: {min_val} - {max_val}")
        print(f"   - çŠ¶æ€: {status}")
        print()

    # 10. å¯è§†åŒ–
    print(f"\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")

    try:
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False

        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('å¥åº·ç›‘æµ‹æ•°æ®åˆ†æ (10ä¸ªæ•°æ®ç‚¹)', fontsize=16, fontweight='bold')

        # 1. å¿ƒç‡è¶‹åŠ¿
        ax1 = axes[0, 0]
        ax1.plot(df['time_point'], df['heart_rate'], 'o-', color='red', linewidth=2, markersize=6)
        ax1.axhline(y=60, color='green', linestyle='--', alpha=0.7, label='æ­£å¸¸ä¸‹é™')
        ax1.axhline(y=100, color='green', linestyle='--', alpha=0.7, label='æ­£å¸¸ä¸Šé™')
        ax1.fill_between(df['time_point'], 60, 100, alpha=0.2, color='green')
        ax1.set_xlabel('æ—¶é—´ç‚¹')
        ax1.set_ylabel('å¿ƒç‡ (bpm)')
        ax1.set_title('å¿ƒç‡å˜åŒ–è¶‹åŠ¿')
        ax1.legend()
        ax1.grid(True, alpha=0.3)

        # 2. è¡€æ°§é¥±å’Œåº¦
        ax2 = axes[0, 1]
        ax2.plot(df['time_point'], df['spo2'], 'o-', color='blue', linewidth=2, markersize=6)
        ax2.axhline(y=95, color='green', linestyle='--', alpha=0.7, label='æ­£å¸¸ä¸‹é™')
        ax2.fill_between(df['time_point'], 95, 100, alpha=0.2, color='green')
        ax2.set_xlabel('æ—¶é—´ç‚¹')
        ax2.set_ylabel('è¡€æ°§é¥±å’Œåº¦ (%)')
        ax2.set_title('è¡€æ°§é¥±å’Œåº¦å˜åŒ–')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        ax2.set_ylim(95, 100)

        # 3. å‘¼å¸é¢‘ç‡
        ax3 = axes[1, 0]
        ax3.plot(df['time_point'], df['respiratory_rate'], 'o-', color='orange', linewidth=2, markersize=6)
        ax3.axhline(y=12, color='green', linestyle='--', alpha=0.7, label='æ­£å¸¸ä¸‹é™')
        ax3.axhline(y=20, color='green', linestyle='--', alpha=0.7, label='æ­£å¸¸ä¸Šé™')
        ax3.fill_between(df['time_point'], 12, 20, alpha=0.2, color='green')
        ax3.set_xlabel('æ—¶é—´ç‚¹')
        ax3.set_ylabel('å‘¼å¸é¢‘ç‡ (æ¬¡/åˆ†)')
        ax3.set_title('å‘¼å¸é¢‘ç‡å˜åŒ–')
        ax3.legend()
        ax3.grid(True, alpha=0.3)

        # 4. ä½“æ¸©
        ax4 = axes[1, 1]
        ax4.plot(df['time_point'], df['temperature'], 'o-', color='purple', linewidth=2, markersize=6)
        ax4.axhline(y=36.1, color='green', linestyle='--', alpha=0.7, label='æ­£å¸¸ä¸‹é™')
        ax4.axhline(y=37.2, color='green', linestyle='--', alpha=0.7, label='æ­£å¸¸ä¸Šé™')
        ax4.fill_between(df['time_point'], 36.1, 37.2, alpha=0.2, color='green')
        ax4.set_xlabel('æ—¶é—´ç‚¹')
        ax4.set_ylabel('ä½“æ¸© (Â°C)')
        ax4.set_title('ä½“æ¸©å˜åŒ–')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        ax4.set_ylim(36.0, 37.5)

        plt.tight_layout()
        plt.savefig('sample_data_analysis.png', dpi=300, bbox_inches='tight')
        print("âœ… å›¾è¡¨å·²ä¿å­˜ä¸º 'sample_data_analysis.png'")

    except Exception as e:
        print(f"âš ï¸  å›¾è¡¨ç”Ÿæˆå¤±è´¥: {str(e)}")

    # 11. é¢„æµ‹ç½®ä¿¡åº¦å¯è§†åŒ–
    print(f"\nğŸ“Š ç”Ÿæˆé¢„æµ‹ç»“æœå›¾è¡¨...")

    try:
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        fig.suptitle('æ¨¡å‹é¢„æµ‹ç»“æœ', fontsize=14, fontweight='bold')

        # é¢„æµ‹æ¦‚ç‡æ¡å½¢å›¾
        ax1.bar(['æ­£å¸¸', 'å¼‚å¸¸'], [normal_prob, abnormal_prob],
                color=['lightgreen', 'lightcoral'], alpha=0.8)
        ax1.set_ylabel('æ¦‚ç‡')
        ax1.set_title('é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ')
        ax1.set_ylim(0, 1)

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        ax1.text(0, normal_prob + 0.02, f'{normal_prob:.3f}', ha='center', fontweight='bold')
        ax1.text(1, abnormal_prob + 0.02, f'{abnormal_prob:.3f}', ha='center', fontweight='bold')

        # é¢„æµ‹ç»“æœé¥¼å›¾
        ax2.pie([normal_prob, abnormal_prob], labels=['æ­£å¸¸', 'å¼‚å¸¸'],
                colors=['lightgreen', 'lightcoral'], autopct='%1.2f%%', startangle=90)
        ax2.set_title('é¢„æµ‹ç»“æœ')

        plt.tight_layout()
        plt.savefig('prediction_result.png', dpi=300, bbox_inches='tight')
        print("âœ… é¢„æµ‹ç»“æœå›¾è¡¨å·²ä¿å­˜ä¸º 'prediction_result.png'")

    except Exception as e:
        print(f"âš ï¸  é¢„æµ‹å›¾è¡¨ç”Ÿæˆå¤±è´¥: {str(e)}")

    # 12. æ€»ç»“
    print(f"\nğŸ’¡ åˆ†ææ€»ç»“:")
    print("=" * 80)

    if predicted_class == 'æ­£å¸¸':
        print("âœ… æ¨¡å‹é¢„æµ‹: æ‚£è€…ç”Ÿå‘½ä½“å¾æ­£å¸¸")
        if confidence > 0.8:
            print("âœ… é¢„æµ‹ç½®ä¿¡åº¦é«˜ï¼Œç»“æœå¯ä¿¡")
        else:
            print("âš ï¸  é¢„æµ‹ç½®ä¿¡åº¦ä¸­ç­‰ï¼Œå»ºè®®ç»§ç»­è§‚å¯Ÿ")
    else:
        print("ğŸ”´ æ¨¡å‹é¢„æµ‹: æ£€æµ‹åˆ°å¼‚å¸¸")
        print("âš ï¸  å»ºè®®è¿›ä¸€æ­¥æ£€æŸ¥å’ŒåŒ»ç–—è¯„ä¼°")

    print(f"\nğŸ“‹ ç”Ÿç†å‚æ•°æ€»ä½“è¯„ä¼°:")

    # æ£€æŸ¥å„å‚æ•°æ˜¯å¦æ­£å¸¸
    hr_normal = np.all((df['heart_rate'] >= 60) & (df['heart_rate'] <= 100))
    spo2_normal = np.all(df['spo2'] >= 95)
    rr_normal = np.all((df['respiratory_rate'] >= 12) & (df['respiratory_rate'] <= 20))
    temp_normal = np.all((df['temperature'] >= 36.1) & (df['temperature'] <= 37.2))

    print(f"   - å¿ƒç‡: {'âœ… æ­£å¸¸' if hr_normal else 'âš ï¸  å¼‚å¸¸'}")
    print(f"   - è¡€æ°§: {'âœ… æ­£å¸¸' if spo2_normal else 'âš ï¸  å¼‚å¸¸'}")
    print(f"   - å‘¼å¸: {'âœ… æ­£å¸¸' if rr_normal else 'âš ï¸  å¼‚å¸¸'}")
    print(f"   - ä½“æ¸©: {'âœ… æ­£å¸¸' if temp_normal else 'âš ï¸  å¼‚å¸¸'}")

    all_normal = hr_normal and spo2_normal and rr_normal and temp_normal

    if all_normal:
        print(f"\nğŸ‰ æ‰€æœ‰ç”Ÿç†å‚æ•°å‡åœ¨æ­£å¸¸èŒƒå›´å†…!")
        print(f"ğŸ’š æ‚£è€…çŠ¶æ€è‰¯å¥½ï¼Œç»§ç»­å¸¸è§„ç›‘æµ‹å³å¯")
    else:
        print(f"\nâš ï¸  éƒ¨åˆ†å‚æ•°è¶…å‡ºæ­£å¸¸èŒƒå›´")
        print(f"ğŸ” å»ºè®®å¯†åˆ‡å…³æ³¨å¼‚å¸¸å‚æ•°çš„å˜åŒ–è¶‹åŠ¿")

    print("\n" + "=" * 80)
    print("âœ… æ ·æœ¬æ•°æ®æµ‹è¯•å®Œæˆ!")
    print("ğŸ“Š ç”Ÿæˆçš„æ–‡ä»¶:")
    print("   - sample_data_analysis.png (ç”Ÿç†å‚æ•°è¶‹åŠ¿å›¾)")
    print("   - prediction_result.png (é¢„æµ‹ç»“æœå›¾)")
    print("=" * 80)


if __name__ == "__main__":
    test_with_sample_data()
